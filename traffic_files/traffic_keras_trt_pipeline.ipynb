{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f1a28e",
   "metadata": {},
   "source": [
    "# Keras Traffic Classification to TensorRT Pipeline\n",
    "\n",
    "This notebook reproduces the data preprocessing from `traffic_classification.ipynb`, trains a TensorFlow/Keras 2D CNN, and exports the model to ONNX and TensorRT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccc663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 18:31:52.373171: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-27 18:31:52.399263: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-27 18:31:52.399284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-27 18:31:52.400028: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-27 18:31:52.405029: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-27 18:31:53.005887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c58ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution:\n",
      "binary_label\n",
      "1    29473\n",
      "0    21040\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_path = \"Data_for_ML_training_Bidirectional\"\n",
    "\n",
    "def load_and_label(pattern, label):\n",
    "    files = glob(os.path.join(data_path, pattern))\n",
    "    dfs = [pd.read_csv(f) for f in files]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df[\"binary_label\"] = label\n",
    "    return df\n",
    "\n",
    "mmtc_df = load_and_label(\"parsed_mmtc*.csv\", 1)\n",
    "embb_df = load_and_label(\"parsed_embb*.csv\", 0)\n",
    "urllc_df = load_and_label(\"parsed_urllc*.csv\", 0)\n",
    "\n",
    "full_df = pd.concat([mmtc_df, embb_df, urllc_df], ignore_index=True)\n",
    "full_df = full_df.drop(columns=[\"amf_ue_ngap_id\", \"ran_ue_id\"])\n",
    "\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(full_df[\"binary_label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d05c729a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized 7 features using MinMaxScaler\n",
      "Class non-mMTC = 21040 samples\n",
      "Class mMTC = 29473 samples\n"
     ]
    }
   ],
   "source": [
    "normalized_df = full_df.copy()\n",
    "feature_cols = [col for col in normalized_df.columns if col != \"binary_label\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_df[feature_cols] = scaler.fit_transform(normalized_df[feature_cols])\n",
    "\n",
    "print(f\"Normalized {len(feature_cols)} features using MinMaxScaler\")\n",
    "\n",
    "label_names = {0: \"non-mMTC\", 1: \"mMTC\"}\n",
    "for c in sorted(normalized_df[\"binary_label\"].unique()):\n",
    "    count = len(normalized_df[normalized_df[\"binary_label\"] == c])\n",
    "    print(f\"Class {label_names[c]} = {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc1a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_binary_slices(df, label_column=\"binary_label\", slice_length=4, step=4, zero_threshold=10):\n",
    "    \"\"\"\n",
    "    Generate time-sliced data from a normalized binary-class dataframe.\n",
    "\n",
    "    Returns:\n",
    "        X: (N, slice_length, F) shaped input data.\n",
    "        y: (N,) labels corresponding to majority class in slice.\n",
    "    \"\"\"\n",
    "    feature_columns = df.columns.drop(label_column)\n",
    "    data = df[feature_columns].values\n",
    "    labels = df[label_column].values\n",
    "\n",
    "    X_slices = []\n",
    "    y_slices = []\n",
    "    for i in range(0, len(df) - slice_length + 1, step):\n",
    "        X_slice = data[i:i+slice_length]\n",
    "        y_slice = labels[i:i+slice_length]\n",
    "\n",
    "        # if check_slice_zero_rows(X_slice, zero_threshold):\n",
    "        #     continue\n",
    "\n",
    "        majority_label = int(round(np.mean(y_slice)))\n",
    "        X_slices.append(X_slice)\n",
    "        y_slices.append(majority_label)\n",
    "    X_slices = np.array(X_slices)\n",
    "    y_slices = np.array(y_slices)\n",
    "\n",
    "    print(f\"Generated {X_slices.shape[0]} slices of shape {X_slices.shape[1:]}\")\n",
    "\n",
    "    unique, counts = np.unique(y_slices, return_counts=True)\n",
    "    for u, c in zip(unique, counts):\n",
    "        print(f\"  Class {u} → {c} samples\")\n",
    "\n",
    "    return X_slices, y_slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f91a4ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 25256 slices of shape (2, 7)\n",
      "  Class 0 → 10520 samples\n",
      "  Class 1 → 14736 samples\n",
      "\n",
      "Training set: 20,204 samples\n",
      "Test set: 5,052 samples\n",
      "Train class distribution: [ 8416 11788]\n",
      "Test class distribution: [2104 2948]\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_binary_slices(normalized_df, slice_length=2, step=2, zero_threshold=65)\n",
    "slice_length = X.shape[1]\n",
    "feature_count = X.shape[2]\n",
    "\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(sss.split(X_flat, y))\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_train = y[train_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "print(f\"\\nTraining set: {len(X_train):,} samples\")\n",
    "print(f\"Test set: {len(X_test):,} samples\")\n",
    "print(f\"Train class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9dc67d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras input shape: (2, 7, 1)\n",
      "X_train_keras shape: (20204, 2, 7, 1)\n",
      "X_test_keras shape: (5052, 2, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_keras = X_train[:, :, :, np.newaxis].astype(\"float32\")\n",
    "X_test_keras = X_test[:, :, :, np.newaxis].astype(\"float32\")\n",
    "y_train_float = y_train.astype(\"float32\")\n",
    "y_test_float = y_test.astype(\"float32\")\n",
    "\n",
    "input_shape = (slice_length, feature_count, 1)\n",
    "\n",
    "print(\"Keras input shape:\", input_shape)\n",
    "print(\"X_train_keras shape:\", X_train_keras.shape)\n",
    "print(\"X_test_keras shape:\", X_test_keras.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51578296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 2, 7, 32)          320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 2, 7, 32)          128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 2, 3, 32)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 2, 3, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 2, 3, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 2, 1, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 1, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 2, 1, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126593 (494.50 KB)\n",
      "Trainable params: 126145 (492.75 KB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 18:31:53.982409: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(1, 2)),\n",
    "    layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(1, 2)),\n",
    "    layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f4e72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "316/316 - 2s - loss: 0.4003 - accuracy: 0.7932 - val_loss: 0.6665 - val_accuracy: 0.6799 - 2s/epoch - 7ms/step\n",
      "Epoch 2/60\n",
      "316/316 - 1s - loss: 0.3588 - accuracy: 0.8100 - val_loss: 0.8299 - val_accuracy: 0.4165 - 1s/epoch - 4ms/step\n",
      "Epoch 3/60\n",
      "316/316 - 1s - loss: 0.3507 - accuracy: 0.8120 - val_loss: 1.3332 - val_accuracy: 0.4153 - 1s/epoch - 4ms/step\n",
      "Epoch 4/60\n",
      "316/316 - 1s - loss: 0.3475 - accuracy: 0.8126 - val_loss: 0.8307 - val_accuracy: 0.4165 - 1s/epoch - 4ms/step\n",
      "Epoch 5/60\n",
      "316/316 - 1s - loss: 0.3455 - accuracy: 0.8145 - val_loss: 1.2389 - val_accuracy: 0.4285 - 1s/epoch - 4ms/step\n",
      "Epoch 6/60\n",
      "316/316 - 1s - loss: 0.3438 - accuracy: 0.8142 - val_loss: 1.6031 - val_accuracy: 0.4165 - 1s/epoch - 4ms/step\n",
      "Epoch 7/60\n",
      "316/316 - 1s - loss: 0.3462 - accuracy: 0.8139 - val_loss: 2.0907 - val_accuracy: 0.6793 - 1s/epoch - 4ms/step\n",
      "Epoch 8/60\n",
      "316/316 - 1s - loss: 0.3424 - accuracy: 0.8156 - val_loss: 1.0268 - val_accuracy: 0.4165 - 1s/epoch - 4ms/step\n",
      "Epoch 9/60\n",
      "316/316 - 1s - loss: 0.3434 - accuracy: 0.8145 - val_loss: 1.1906 - val_accuracy: 0.4165 - 1s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=8,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_keras,\n",
    "    y_train_float,\n",
    "    validation_data=(X_test_keras, y_test_float),\n",
    "    epochs=60,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a839952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6665\n",
      "Test Accuracy: 0.6799\n",
      "158/158 [==============================] - 0s 1ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non-mMTC       0.96      0.24      0.39      2104\n",
      "        mMTC       0.65      0.99      0.78      2948\n",
      "\n",
      "    accuracy                           0.68      5052\n",
      "   macro avg       0.80      0.62      0.58      5052\n",
      "weighted avg       0.78      0.68      0.62      5052\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 507 1597]\n",
      " [  20 2928]]\n"
     ]
    }
   ],
   "source": [
    "eval_loss, eval_acc = model.evaluate(X_test_keras, y_test_float, verbose=0)\n",
    "print(f\"Test Loss: {eval_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {eval_acc:.4f}\")\n",
    "\n",
    "y_pred_probs = model.predict(X_test_keras).ravel()\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"non-mMTC\", \"mMTC\"]))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ee1873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Keras model to traffic_cnn_keras.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vs24436/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "h5_path = \"traffic_cnn_keras.h5\"\n",
    "model.save(h5_path)\n",
    "print(\"Saved Keras model to\", h5_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21e7e09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ONNX model to traffic_cnn_keras.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 18:32:07.012406: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\n",
      "2025-09-27 18:32:07.012480: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-09-27 18:32:07.138071: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-09-27 18:32:07.184888: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\n",
      "2025-09-27 18:32:07.184986: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-09-27 18:32:07.185410: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tf2onnx\n",
    "\n",
    "onnx_path = \"traffic_cnn_keras.onnx\"\n",
    "\n",
    "input_signature = (\n",
    "    tf.TensorSpec(\n",
    "        [None, slice_length, feature_count, 1],\n",
    "        tf.float32,\n",
    "        name=model.inputs[0].name.split(\":\")[0],\n",
    "    ),\n",
    ")\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    model,\n",
    "    input_signature=input_signature,\n",
    "    opset=13,\n",
    ")\n",
    "\n",
    "with open(onnx_path, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"Saved ONNX model to\", onnx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98c4d228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TensorRT engine to traffic_cnn_keras.trt\n"
     ]
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "trt_logger = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "def build_trt_engine(onnx_file_path, engine_file_path, max_ws=1 << 30, fp16=True):\n",
    "    with trt.Builder(trt_logger) as builder, \\\n",
    "         builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "         trt.OnnxParser(network, trt_logger) as parser:\n",
    "        config = builder.create_builder_config()\n",
    "        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, max_ws)\n",
    "        if fp16 and builder.platform_has_fast_fp16:\n",
    "            config.set_flag(trt.BuilderFlag.FP16)\n",
    "\n",
    "        with open(onnx_file_path, \"rb\") as f:\n",
    "            if not parser.parse(f.read()):\n",
    "                for idx in range(parser.num_errors):\n",
    "                    print(parser.get_error(idx))\n",
    "                raise RuntimeError(\"Failed to parse ONNX model\")\n",
    "\n",
    "        input_tensor = network.get_input(0)\n",
    "        min_shape = (1, slice_length, feature_count, 1)\n",
    "        opt_batch = min(16, max(1, X_train_keras.shape[0]))\n",
    "        max_batch = max(opt_batch, 32)\n",
    "        opt_shape = (opt_batch, slice_length, feature_count, 1)\n",
    "        max_shape = (max_batch, slice_length, feature_count, 1)\n",
    "\n",
    "        profile = builder.create_optimization_profile()\n",
    "        profile.set_shape(input_tensor.name, min_shape, opt_shape, max_shape)\n",
    "        config.add_optimization_profile(profile)\n",
    "\n",
    "        engine_bytes = builder.build_serialized_network(network, config)\n",
    "        if engine_bytes is None:\n",
    "            raise RuntimeError(\"Engine build failed\")\n",
    "\n",
    "        with open(engine_file_path, \"wb\") as f:\n",
    "            f.write(engine_bytes)\n",
    "        print(\"Saved TensorRT engine to\", engine_file_path)\n",
    "\n",
    "trt_engine_path = \"traffic_cnn_keras.trt\"\n",
    "build_trt_engine(onnx_path, trt_engine_path, fp16=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
